# Logstash S3 VPC Flow Logs Raw configuration

# Read VPC Flow Logs from S3 bucket and define the sourcetype
input {
  s3 {
    bucket => "awsianp-us-east-1-vpc-flow-logs-test"
    prefix => "AWSLogs/51"
    region => "us-east-1"
    temporary_directory => "/data/logstash/tmp/raw/"
    sincedb_path => "/var/lib/logstash/plugins/inputs/s3/awsianpraw"
    add_field => {"sourcetype" => "vpc_raw"}
    id => "s3_vpcflowlogs_raw"
#    additional_settings => {
#      "follow_redirects" => false
#      "force_path_style" => true
#    }
  }
}


filter {
  if [sourcetype] == "vpc_raw" {

    # Discard messages without data TODO: We should probably send these as is without processing instead
    if "SKIPDATA" in [message] or "NODATA" in [message] {
      drop {}
    }

    # Parse each message based on custom VPC Flow Log format
    csv {
      id => "s3_vpcflowlogs_raw_csv"
      source => "message"
      separator => " "
      autogenerate_column_names => false
      skip_header => true
      columns => [ "version", "account-id", "interface-id", "srcaddr", "dstaddr", "srcport", "dstport", "protocol", "packets", "bytes", "start", "end", "action", "log-status", "vpc-id", "subnet-id", "instance-id", "pkt-srcaddr", "pkt-dstaddr", "tcp-flags", "type"
      ]
      # Convert method in csv filter is not working as expected
      #               convert => {
      #                       "packets" => "integer"
      #                       "bytes" => "integer"
      #                       "start" => "integer"
      #                       "end" => "integer"
      #               }
    }

    # Drop any messages without an account-id TODO: This should not happen anymore - remove
#    if ![account-id] {
#      drop {}
#    }

    # Hash each message identifying unique flows
    fingerprint {
      id => "s3_vpcflowlogs_raw_fingerprint"
      concatenate_sources => true
      key => "flows"
      method => "SHA1"
      source => [
              "vpc-id", "srcaddr", "dstaddr", "srcport", "dstport", "protocol", "action"
      ]
      remove_field => ["message"]
    }

    # Transform significant fields - TODO: Could be removed as only relevant for optimization
    if [start] {
      mutate {
        convert => {
          "start" => "integer"
        }
      }
      date {
        match => ["start", "UNIX"]
        target => "@timestamp"
      }
    }
    if [packets] {
      mutate {
        convert => {
          "packets" => "integer"
        }
      }
    }
    if [bytes] {
      mutate {
        convert => {
          "bytes" => "integer"
        }
      }
    }
    if [end] {
      mutate {
        convert => {
          "end" => "integer"
        }
      }
    }
  }
}

# Send data to elasticsearch for analysis
output {
  if [sourcetype] == "vpc_raw" {
    elasticsearch {
      hosts => ["localhost:9200"]
      id => "s3_vpcflowlogs_raw_es"
      index => "vpcflow-raw-01-%{+YYYY.MM.dd}"
    }
  }
  else if [sourcetype] == "vpc_raw" and [tags] {
    stdout {
      codec => rubydebug
    }
  }
}
